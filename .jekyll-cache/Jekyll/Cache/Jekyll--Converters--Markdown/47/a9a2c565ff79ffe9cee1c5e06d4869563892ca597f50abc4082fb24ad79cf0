I"õ)<body style="background-color: #28423b">

<a href="https://offensive-ai-lab.github.io/"><svg id="d3banner"></svg></a>

<script src="https://d3js.org/d3.v5.min.js"></script>
<script>
  // ported from https://bl.ocks.org/mbostock/3231298
  // adapted from https://github.com/columbiaviz/columbiaviz.github.io

window.mobileCheck = function() {
  let check = false;
  (function(a){if(/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(a)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0,4))) check = true;})(navigator.userAgent||navigator.vendor||window.opera);
  return check;
};



  var width =  document.getElementsByTagName("div")[0].offsetWidth ;
  var height = width > 500 ? 300 : 180;
  var strength = width > 500 ? 0.05 : 0.15;

  var numNodes = 200;
  var nodes = d3.range(numNodes).map(() => ({radius: Math.random() * 10+1}));
  var root = nodes[0],
      colorBad =  d3.scaleSequential(d3.interpolateOrRd),
	  colorGood =  d3.scaleSequential(d3.interpolateGreys);

  root.radius = 0;
  root.fixed = true;
  
  var toggle = -1;

  const svg = d3.select("#d3banner")
      .attr("width", width)
      .attr("height", height);

  const simulation = d3.forceSimulation(nodes)
      .force('charge', d3.forceManyBody().strength((d, i) => i ? 0 : -2000))
      .force('x', d3.forceX(width / 2).strength(strength))
      .force('y', d3.forceY(height / 2).strength(strength))
      .force('collision', d3.forceCollide().radius(d => d.radius))
      .on('tick', ticked);

  svg.selectAll("circle")
      .data(nodes.slice(1))
      .enter().append("circle")
      .attr("r", d => d.radius)
      .attr("opacity", 0.7)
      .style("fill", (d, i) => colorGood(i / (numNodes*2) +.2));

  svg.on("mousemove", function() {
      var p1 = d3.mouse(this);
      root.fx = p1[0];
      root.fy = p1[1];
      simulation
          .alphaTarget(0.3)
          .restart();
    });
	
  svg.on("touchmove", function() {
      var p1 = d3.mouse(this);
      root.fx = p1[0];
      root.fy = p1[1];
      simulation
          .alphaTarget(0.3)
          .restart();
    });

  function ticked() {
      svg.selectAll("circle")
          .attr("cx", d => d.x)
          .attr("cy", d => d.y);
  }
       
      root.fx = 100;
      root.fy = 100;
      simulation
          .alphaTarget(0.3)
          .restart();
  
 setInterval(function() 
 
 {
	toggle = toggle * -1;
	
	
	
    simulation.force('charge', d3.forceManyBody().strength((d, i) => i ? 0 : toggle*2000))
	
	if(toggle>0){
	svg.selectAll("circle")
      .data(nodes.slice(1))
      .style("fill", (d, i) => colorBad(i / (numNodes*2)+.5));
	}else{
	svg.selectAll("circle")
      .data(nodes.slice(1))
      .style("fill", (d, i) => colorGood(i / (numNodes*2)+.2));
	
	}
	
	
	}

	, 6000);

</script>

Welcome to the course site for `Offensive AI` <script>document.write(new Date().getFullYear())</script> which I teach at BGU in the Department of Software and Information Systems Engineering.  Below you will find the course syllabus and more content will be added over the semester.





### Syllabus 

**Course Name**: Offensive AI<br />
 **Course Name (Hebrew)**: ◊ë◊ô◊†◊î ◊û◊ú◊ê◊õ◊ï◊™◊ô◊™ ◊ñ◊ì◊ï◊†◊ô◊™<br />
 **Course Number**: TBA<br />
 **Course Structure**: 3 hours of lectures weekly<br />
 **Course Credits**: 3<br />
 **Lecturer**: Dr. Yisroel Mirsky<br />

**Course Description:**

Artificial intelligence (AI) has provided us with the ability to automate tasks, extract information from vast amounts of data, and synthesize media that is nearly indistinguishable from the real thing. However, positive tools can also be used for negative purposes. In particular, cyber adversaries can also use AI, but to enhance their attacks and expand their campaigns.

In this course we will learn about attacks against AI systems (adversarial machine learning) such as model poisoning, model inversion, mebership inference, trojaning, and adversrial examples. We will also learn about attacks which use AI, such as deepfakes for facial reenactment and voice cloning, advanced spyware, autnomous bots, evasive malware, and the use of machine leanrning to detect software vulnerabilities. Finally, throughout the course we will learn how we can defend against these attacks and learn the best pratices for developing systems which are robust against them too. 

**Purpose of the Course:**

The goal of the course is to learn (1) how AI is being used by malicious actors to exploit our AI systems and enhance their cyberattacks, and (2) how we can defend against these threats and develop safer systems.

**Prerequisites:**

At least one course in machine learning (e.g., 372.1.4951, 372.1.4952, 372.2.5910) or relevant experience in the subject. The course is open to students outside of the department on the basis of availability and faculty member recommendation.

**Course Requirements**:

- Attendance is required.
- Students must learn the course from the lectures and any provided written materials.
- Students will submit one practical exercise in Python (10% of the grade), and one project which will be presented in the final lecture (15% of the grade).
- The final exam is 75% of the grade. Passing the exam is required for passing the course. 

**Lectures:** (There may be small modifications)

| **Week** | **Topic**                                                    |
| -------- | ------------------------------------------------------------ |
| 1        | Introduction to machine learning and offensive AI.           |
|          | **Attacks on AI**                                            |
| 2        | Adversarial Machine Learning I (Causative Attacks):    Dataset poisoning and fault attacks (e.g., neural trojans, defense evasion,  allergy attacks, clustering attacks). |
| 3        | Adversarial Machine Learning II (Exploratory Attacks):     Adversarial examples, sponge examples, model inversion, membership inference,  and parameter inference. |
| 4        | Prevention and Mitigation of Adversarial Machine Learning    |
| 5        | Lab: Adversarial Machine Learning with libraries and  Torch in Python |
|          | **Attacks using AI: Deepfakes**                              |
| 6        | Deepfakes I:    Ethics of deepfakes and Generative AI used for facial reenactment |
| 7        | Deepfakes II:    Generative AI used for face replacement, face synthesis, and record tampering |
| 8        | Deepfakes III:    Generative AI for voice cloning, spoofing, and audio driven reenactment |
| 9        | Detection, Prevention, and Mitigation of Deepfakes           |
|          | **Attacks using AI: Attack  Tools**                          |
| 10       | Attack Planning and Exploit Development                      |
| 11       | Spyware and Credential Theft                                 |
| 12       | Intelligent Bots, Swarms, Detection Evasion, and Campaign  Automation |
|          | **Course Conclusion**                                        |
| 13       | Student project presentations                                |

 

**Reading List:** (tentative)

1. Huang, Ling, et al. "Adversarial machine learning." *Proceedings of the 4th ACM workshop on Security and artificial intelligence*. 2011.
2. Biggio, Battista, and Fabio Roli. "Wild patterns: Ten years after the rise of adversarial machine learning." *Pattern Recognition* 84 (2018): 317-331.
3. Zhang, Jiliang, and Chen Li. "Adversarial examples: Opportunities and challenges." *IEEE transactions on neural networks and learning systems* 31.7 (2019): 2578-2593.
4. Carlini, Nicholas, et al. "On evaluating adversarial robustness." *arXiv preprint arXiv:1902.06705* (2019).
5. Ilyas, Andrew, et al. "Adversarial examples are not bugs, they are features." *arXiv preprint arXiv:1905.02175* (2019).
6. Liu, Yuntao, et al. "A survey on neural trojans." *2020 21st International Symposium on Quality Electronic Design (ISQED)*. IEEE, 2020.
7. Chen, Huili, et al. "DeepInspect: A Black-box Trojan Detection and Mitigation Framework for Deep Neural Networks." *IJCAI*. 2019.
8. Mirsky, Yisroel, and Wenke Lee. "The creation and detection of deepfakes: A survey." *ACM Computing Surveys (CSUR)* 54.1 (2021): 1-41.
9. Tolosana, Ruben, et al. "Deepfakes and beyond: A survey of face manipulation and fake detection." *Information Fusion* 64 (2020): 131-148.
10. Arik, Sercan O., et al. "Neural voice cloning with a few samples." *arXiv preprint arXiv:1802.06006* (2018).
11. Hettwer, Benjamin, Stefan Gehrer, and Tim G√ºneysu. "Applications of machine learning techniques in side-channel attacks: a survey." *Journal of Cryptographic Engineering* 10.2 (2020): 135-162.
12. Batina, Lejla, et al. "{CSI}{NN}: Reverse Engineering of Neural Network Architectures Through Electromagnetic Side Channel." *28th {USENIX} Security Symposium ({USENIX} Security 19)*. 2019.
</body>
:ET